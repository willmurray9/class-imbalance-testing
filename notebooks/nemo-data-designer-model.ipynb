{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c77dcc",
   "metadata": {},
   "source": [
    "# NeMo Data Designer for Stroke Prediction Class Imbalance\n",
    "\n",
    "Using NeMo Data Designer to generate synthetic stroke patients (minority class augmentation)\n",
    "\n",
    "**âš ï¸ Important Workflow Note:**\n",
    "- This notebook uses **UNSCALED** data (real ages, glucose levels, BMI) for NDD generation\n",
    "- The LLM validation evaluates medical plausibility with actual values (age=67, not 0.72)\n",
    "- After generation, we **scale** the synthetic samples using the same `RobustScaler` fitted during feature engineering\n",
    "- Finally, we combine **scaled** synthetic + **scaled** original data for model training\n",
    "- This ensures the LLM can meaningfully evaluate medical coherence while maintaining proper ML preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae9247",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753eee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    average_precision_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"All packages loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0c0abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ NeMo Data Designer client initialized!\n",
      "âœ“ Using model: nemotron-super\n"
     ]
    }
   ],
   "source": [
    "from nemo_microservices.data_designer.essentials import (\n",
    "    CategorySamplerParams,\n",
    "    DataDesignerConfigBuilder,\n",
    "    LLMTextColumnConfig,\n",
    "    NeMoDataDesignerClient,\n",
    "    UniformSamplerParams,\n",
    "    SamplerColumnConfig,\n",
    "    SamplerType,\n",
    ")\n",
    "\n",
    "data_designer_client = NeMoDataDesignerClient(\n",
    "    base_url=\"https://ai.api.nvidia.com/v1/nemo/dd\",\n",
    "    default_headers={\"Authorization\": f\"Bearer {os.getenv('NVIDIA_API_KEY')}\"}\n",
    ")\n",
    "\n",
    "model_alias = \"nemotron-super\"  \n",
    "\n",
    "print(f\"âœ“ NeMo Data Designer client initialized!\")\n",
    "print(f\"âœ“ Using model: {model_alias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241cb26",
   "metadata": {},
   "source": [
    "## 2. Load and Analyze Data\n",
    "\n",
    "We need to understand the distributions of stroke patients to configure our NDD samplers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613e20e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dataset shape: (5110, 17)\n",
      "\n",
      "ğŸ“‹ Features (17 total):\n",
      "   ['id', 'age', 'avg_glucose_level', 'bmi', 'stroke', 'gender_Male', 'hypertension_Yes', 'heart_disease_Yes', 'ever_married_Yes', 'work_type_Never_worked', 'work_type_Private', 'work_type_Self-employed', 'work_type_children', 'Residence_type_Urban', 'smoking_status_formerly smoked', 'smoking_status_never smoked', 'smoking_status_smokes']\n",
      "\n",
      "ğŸ” Using UNSCALED data for NDD (real ages, glucose, BMI)\n",
      "   This allows LLM to evaluate medical plausibility with actual values\n",
      "\n",
      "ğŸ“ˆ Class distribution:\n",
      "stroke\n",
      "0    4861\n",
      "1     249\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ“Š Class distribution (%):\n",
      "stroke\n",
      "0    95.127202\n",
      "1     4.872798\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "âœ“ Stroke cases: 249 (4.87%)\n",
      "âœ“ Non-stroke cases: 4861 (95.13%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>hypertension_Yes</th>\n",
       "      <th>heart_disease_Yes</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>67.0</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>61.0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>80.0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>49.0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>79.0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   age  avg_glucose_level   bmi  stroke  gender_Male  \\\n",
       "0   9046  67.0             228.69  36.6       1            1   \n",
       "1  51676  61.0             202.21  28.1       1            0   \n",
       "2  31112  80.0             105.92  32.5       1            1   \n",
       "3  60182  49.0             171.23  34.4       1            0   \n",
       "4   1665  79.0             174.12  24.0       1            0   \n",
       "\n",
       "   hypertension_Yes  heart_disease_Yes  ever_married_Yes  \\\n",
       "0                 0                  1                 1   \n",
       "1                 0                  0                 1   \n",
       "2                 0                  1                 1   \n",
       "3                 0                  0                 1   \n",
       "4                 1                  0                 1   \n",
       "\n",
       "   work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
       "0                       0                  1                        0   \n",
       "1                       0                  0                        1   \n",
       "2                       0                  1                        0   \n",
       "3                       0                  1                        0   \n",
       "4                       0                  0                        1   \n",
       "\n",
       "   work_type_children  Residence_type_Urban  smoking_status_formerly smoked  \\\n",
       "0                   0                     1                               1   \n",
       "1                   0                     0                               0   \n",
       "2                   0                     0                               0   \n",
       "3                   0                     1                               0   \n",
       "4                   0                     0                               0   \n",
       "\n",
       "   smoking_status_never smoked  smoking_status_smokes  \n",
       "0                            0                      0  \n",
       "1                            1                      0  \n",
       "2                            1                      0  \n",
       "3                            0                      1  \n",
       "4                            1                      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load UNSCALED data for NeMo Data Designer\n",
    "# NDD needs real values (age in years, glucose in mg/dL, BMI) for LLM validation\n",
    "df = pd.read_csv('../data/stroke_data_unscaled.csv')\n",
    "\n",
    "print(f\"ğŸ“Š Dataset shape: {df.shape}\")\n",
    "print(f\"\\nğŸ“‹ Features ({len(df.columns)} total):\")\n",
    "print(f\"   {df.columns.tolist()}\")\n",
    "print(f\"\\nğŸ” Using UNSCALED data for NDD (real ages, glucose, BMI)\")\n",
    "print(f\"   This allows LLM to evaluate medical plausibility with actual values\")\n",
    "print(f\"\\nğŸ“ˆ Class distribution:\")\n",
    "print(df['stroke'].value_counts())\n",
    "print(f\"\\nğŸ“Š Class distribution (%):\")\n",
    "print(df['stroke'].value_counts(normalize=True) * 100)\n",
    "\n",
    "stroke_cases = df[df['stroke'] == 1]\n",
    "non_stroke_cases = df[df['stroke'] == 0]\n",
    "\n",
    "print(f\"\\nâœ“ Stroke cases: {len(stroke_cases)} ({len(stroke_cases)/len(df)*100:.2f}%)\")\n",
    "print(f\"âœ“ Non-stroke cases: {len(non_stroke_cases)} ({len(non_stroke_cases)/len(df)*100:.2f}%)\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69fa401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Numerical Feature Statistics - STROKE PATIENTS (UNSCALED)\n",
      "======================================================================\n",
      "              age  avg_glucose_level         bmi\n",
      "count  249.000000         249.000000  249.000000\n",
      "mean    67.728193         132.544739   30.090361\n",
      "std     12.727419          61.921056    5.861877\n",
      "min      1.320000          56.110000   16.900000\n",
      "25%     59.000000          79.790000   27.000000\n",
      "50%     71.000000         105.220000   28.100000\n",
      "75%     78.000000         196.710000   32.500000\n",
      "max     82.000000         271.740000   56.600000\n",
      "\n",
      "â„¹ï¸  These are REAL values:\n",
      "   - Age: in years\n",
      "   - Glucose: in mg/dL\n",
      "   - BMI: body mass index\n",
      "\n",
      "======================================================================\n",
      "Numerical Feature Statistics - NON-STROKE PATIENTS (UNSCALED)\n",
      "======================================================================\n",
      "               age  avg_glucose_level          bmi\n",
      "count  4861.000000        4861.000000  4861.000000\n",
      "mean     41.971545         104.795513    28.799115\n",
      "std      22.291940          43.846069     7.777269\n",
      "min       0.080000          55.120000    10.300000\n",
      "25%      24.000000          77.120000    23.600000\n",
      "50%      43.000000          91.470000    28.100000\n",
      "75%      59.000000         112.830000    32.800000\n",
      "max      82.000000         267.760000    97.600000\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Numerical Feature Statistics - STROKE PATIENTS (UNSCALED)\")\n",
    "print(\"=\" * 70)\n",
    "print(stroke_cases[['age', 'avg_glucose_level', 'bmi']].describe())\n",
    "print(\"\\nâ„¹ï¸  These are REAL values:\")\n",
    "print(\"   - Age: in years\")\n",
    "print(\"   - Glucose: in mg/dL\")\n",
    "print(\"   - BMI: body mass index\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Numerical Feature Statistics - NON-STROKE PATIENTS (UNSCALED)\")\n",
    "print(\"=\" * 70)\n",
    "print(non_stroke_cases[['age', 'avg_glucose_level', 'bmi']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a6403",
   "metadata": {},
   "source": [
    "### Categorical Feature Distributions for Stroke Patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e15915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Feature Distributions (Stroke Patients):\n",
      "======================================================================\n",
      "\n",
      "gender_Male:\n",
      "  0: 56.63%\n",
      "  1: 43.37%\n",
      "\n",
      "hypertension_Yes:\n",
      "  0: 73.49%\n",
      "  1: 26.51%\n",
      "\n",
      "heart_disease_Yes:\n",
      "  0: 81.12%\n",
      "  1: 18.88%\n",
      "\n",
      "ever_married_Yes:\n",
      "  0: 11.65%\n",
      "  1: 88.35%\n",
      "\n",
      "Residence_type_Urban:\n",
      "  0: 45.78%\n",
      "  1: 54.22%\n",
      "\n",
      "======================================================================\n",
      "Work Type Distribution (Stroke Patients):\n",
      "======================================================================\n",
      "  work_type_Never_worked: 0.00%\n",
      "  work_type_Private: 59.84%\n",
      "  work_type_Self-employed: 26.10%\n",
      "  work_type_children: 0.80%\n",
      "\n",
      "======================================================================\n",
      "Smoking Status Distribution (Stroke Patients):\n",
      "======================================================================\n",
      "  smoking_status_formerly smoked: 28.11%\n",
      "  smoking_status_never smoked: 36.14%\n",
      "  smoking_status_smokes: 16.87%\n"
     ]
    }
   ],
   "source": [
    "# Analyze categorical feature distributions for stroke patients\n",
    "binary_features = ['gender_Male', 'hypertension_Yes', 'heart_disease_Yes', \n",
    "                    'ever_married_Yes', 'Residence_type_Urban']\n",
    "\n",
    "print(\"Binary Feature Distributions (Stroke Patients):\")\n",
    "print(\"=\" * 70)\n",
    "for feature in binary_features:\n",
    "    dist = stroke_cases[feature].value_counts(normalize=True)\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(f\"  0: {dist.get(0, 0):.2%}\")\n",
    "    print(f\"  1: {dist.get(1, 0):.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Work Type Distribution (Stroke Patients):\")\n",
    "print(\"=\" * 70)\n",
    "work_cols = ['work_type_Never_worked', 'work_type_Private', 'work_type_Self-employed', 'work_type_children']\n",
    "for col in work_cols:\n",
    "    pct = stroke_cases[col].sum() / len(stroke_cases)\n",
    "    print(f\"  {col}: {pct:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Smoking Status Distribution (Stroke Patients):\")\n",
    "print(\"=\" * 70)\n",
    "smoking_cols = ['smoking_status_formerly smoked', 'smoking_status_never smoked', 'smoking_status_smokes']\n",
    "for col in smoking_cols:\n",
    "    pct = stroke_cases[col].sum() / len(stroke_cases)\n",
    "    print(f\"  {col}: {pct:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f94c78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecfa9b14",
   "metadata": {},
   "source": [
    "## 3. Configure NeMo Data Designer\n",
    "\n",
    "Now we'll configure NDD samplers based on the stroke patient distributions we just analyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74815ead",
   "metadata": {},
   "source": [
    "### Step 1: Initialize Config Builder and Configure Numerical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0230a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸  Configuring NDD samplers for synthetic stroke patients...\n",
      "\n",
      "1ï¸âƒ£ Adding numerical features (UNSCALED - real values)...\n",
      "   Age: 1.3 - 82.0 years\n",
      "   Glucose: 56.1 - 271.7 mg/dL\n",
      "   BMI: 16.9 - 56.6\n",
      "\n",
      "âœ“ Numerical features configured with REAL VALUES\n"
     ]
    }
   ],
   "source": [
    "# Initialize configuration builder\n",
    "config_builder = DataDesignerConfigBuilder()\n",
    "\n",
    "print(\"âš™ï¸  Configuring NDD samplers for synthetic stroke patients...\")\n",
    "print(\"\\n1ï¸âƒ£ Adding numerical features (UNSCALED - real values)...\")\n",
    "\n",
    "# Add Age (unscaled - in years)\n",
    "age_min = float(stroke_cases['age'].min())\n",
    "age_max = float(stroke_cases['age'].max())\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"age\",\n",
    "        sampler_type=SamplerType.UNIFORM,\n",
    "        params=UniformSamplerParams(low=age_min, high=age_max),\n",
    "    )\n",
    ")\n",
    "print(f\"   Age: {age_min:.1f} - {age_max:.1f} years\")\n",
    "\n",
    "# Add Average Glucose Level (unscaled - in mg/dL)\n",
    "glucose_min = float(stroke_cases['avg_glucose_level'].min())\n",
    "glucose_max = float(stroke_cases['avg_glucose_level'].max())\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"avg_glucose_level\",\n",
    "        sampler_type=SamplerType.UNIFORM,\n",
    "        params=UniformSamplerParams(low=glucose_min, high=glucose_max),\n",
    "    )\n",
    ")\n",
    "print(f\"   Glucose: {glucose_min:.1f} - {glucose_max:.1f} mg/dL\")\n",
    "\n",
    "# Add BMI (unscaled - body mass index)\n",
    "bmi_min = float(stroke_cases['bmi'].min())\n",
    "bmi_max = float(stroke_cases['bmi'].max())\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"bmi\",\n",
    "        sampler_type=SamplerType.UNIFORM,\n",
    "        params=UniformSamplerParams(low=bmi_min, high=bmi_max),\n",
    "    )\n",
    ")\n",
    "print(f\"   BMI: {bmi_min:.1f} - {bmi_max:.1f}\")\n",
    "\n",
    "print(\"\\nâœ“ Numerical features configured with REAL VALUES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81434fc",
   "metadata": {},
   "source": [
    "### Step 2: Configure Binary Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d71c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ï¸âƒ£ Adding binary categorical features...\n",
      "âœ“ Configured 5 binary features\n"
     ]
    }
   ],
   "source": [
    "print(\"2ï¸âƒ£ Adding binary categorical features...\")\n",
    "\n",
    "binary_features = ['gender_Male', 'hypertension_Yes', 'heart_disease_Yes', \n",
    "                    'ever_married_Yes', 'Residence_type_Urban']\n",
    "\n",
    "for feature in binary_features:\n",
    "    dist = stroke_cases[feature].value_counts(normalize=True).to_dict()\n",
    "    config_builder.add_column(\n",
    "        SamplerColumnConfig(\n",
    "            name=feature,\n",
    "            sampler_type=SamplerType.CATEGORY,\n",
    "            params=CategorySamplerParams(\n",
    "                values=[0, 1],\n",
    "                weights=[dist.get(0, 0.5), dist.get(1, 0.5)]\n",
    "            ),\n",
    "            convert_to=\"int\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "print(f\"âœ“ Configured {len(binary_features)} binary features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d5164",
   "metadata": {},
   "source": [
    "### Step 3: Configure Multi-Class Categorical Features (Work Type & Smoking Status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d745d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ï¸âƒ£ Adding multi-class categorical features...\n",
      "âœ“ Work type and smoking status configured\n"
     ]
    }
   ],
   "source": [
    "print(\"3ï¸âƒ£ Adding multi-class categorical features...\")\n",
    "\n",
    "# Work Type\n",
    "work_types = [\"Never_worked\", \"Private\", \"Self-employed\", \"children\"]\n",
    "work_weights = [\n",
    "    stroke_cases['work_type_Never_worked'].sum() / len(stroke_cases),\n",
    "    stroke_cases['work_type_Private'].sum() / len(stroke_cases),\n",
    "    stroke_cases['work_type_Self-employed'].sum() / len(stroke_cases),\n",
    "    stroke_cases['work_type_children'].sum() / len(stroke_cases),\n",
    "]\n",
    "\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"work_type\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=work_types,\n",
    "            weights=work_weights\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Smoking Status\n",
    "smoking_statuses = [\"formerly smoked\", \"never smoked\", \"smokes\"]\n",
    "smoking_weights = [\n",
    "    stroke_cases['smoking_status_formerly smoked'].sum() / len(stroke_cases),\n",
    "    stroke_cases['smoking_status_never smoked'].sum() / len(stroke_cases),\n",
    "    stroke_cases['smoking_status_smokes'].sum() / len(stroke_cases),\n",
    "]\n",
    "\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"smoking_status\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=smoking_statuses,\n",
    "            weights=smoking_weights\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"âœ“ Work type and smoking status configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2e88d",
   "metadata": {},
   "source": [
    "### Step 4: (Optional) Add LLM Medical Coherence Validation\n",
    "\n",
    "This is NDD's unique strength - using an LLM to ensure feature combinations make medical sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b4a33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ï¸âƒ£ Adding LLM medical coherence validation...\n",
      "âœ“ LLM validation configured - will generate plausibility scores (1-10)\n",
      "   LLM will see ACTUAL medical values (age in years, glucose in mg/dL, etc.)\n",
      "\n",
      "âœ… Configuration complete!\n"
     ]
    }
   ],
   "source": [
    "# Set to True to enable LLM-based medical coherence check (slower, more expensive, but validates data quality)\n",
    "use_llm_validation = True  # Change to False to skip\n",
    "\n",
    "if use_llm_validation:\n",
    "    print(\"4ï¸âƒ£ Adding LLM medical coherence validation...\")\n",
    "    \n",
    "    config_builder.add_column(\n",
    "        LLMTextColumnConfig(\n",
    "            name=\"medical_plausibility\",\n",
    "            prompt=(\n",
    "                \"Given a stroke patient with:\\\\n\"\n",
    "                \"- Age: {{ age }} years\\\\n\"\n",
    "                \"- Average glucose level: {{ avg_glucose_level }} mg/dL\\\\n\"\n",
    "                \"- BMI: {{ bmi }}\\\\n\"\n",
    "                \"- Hypertension: {{ hypertension_Yes }} (0=No, 1=Yes)\\\\n\"\n",
    "                \"- Heart disease: {{ heart_disease_Yes }} (0=No, 1=Yes)\\\\n\"\n",
    "                \"- Smoking status: {{ smoking_status }}\\\\n\\\\n\"\n",
    "                \"Rate the medical plausibility of this combination (1-10). \"\n",
    "                \"Higher scores mean more realistic/typical stroke patient profile. \"\n",
    "                \"Consider how these risk factors commonly occur together in actual stroke patients. \"\n",
    "                \"Respond with ONLY a number from 1 to 10.\"\n",
    "            ),\n",
    "            system_prompt=(\n",
    "                \"You are a medical expert evaluating stroke patient profiles. \"\n",
    "                \"Consider realistic medical scenarios and how risk factors \"\n",
    "                \"(age, glucose, BMI, hypertension, heart disease, smoking) \"\n",
    "                \"typically present together in actual stroke patients.\"\n",
    "            ),\n",
    "            model_alias=model_alias,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(\"âœ“ LLM validation configured - will generate plausibility scores (1-10)\")\n",
    "    print(\"   LLM will see ACTUAL medical values (age in years, glucose in mg/dL, etc.)\")\n",
    "else:\n",
    "    print(\"4ï¸âƒ£ Skipping LLM validation\")\n",
    "\n",
    "print(\"\\nâœ… Configuration complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43d1cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_plausibility_score(text):\n",
    "    \"\"\"\n",
    "    Extract numeric plausibility score (1-10) from LLM response\n",
    "    Handles responses with <think> tags and explanations\n",
    "    \n",
    "    The LLM may include its thinking process in <think>...</think> tags,\n",
    "    followed by the final numeric score. This function extracts just the number.\n",
    "    \n",
    "    Args:\n",
    "        text: Raw LLM response text\n",
    "        \n",
    "    Returns:\n",
    "        Numeric score (1-10) or NaN if extraction fails\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Remove <think>...</think> tags and their content\n",
    "    text_cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # Find all numbers in the remaining text (after removing think tags)\n",
    "    numbers = re.findall(r'\\b([1-9]|10)\\b', text_cleaned)\n",
    "    \n",
    "    if numbers:\n",
    "        # Return the first valid number found (should be the final answer)\n",
    "        return int(numbers[0])\n",
    "    \n",
    "    # Fallback: try to find any number (1-10) in original text\n",
    "    numbers = re.findall(r'\\b([1-9]|10)\\b', text)\n",
    "    if numbers:\n",
    "        return int(numbers[0])\n",
    "    \n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585ce4d",
   "metadata": {},
   "source": [
    "## 4. Generate Preview (Test Configuration)\n",
    "\n",
    "First, generate a small preview to verify everything works correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04831cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:30:21] [INFO] âœ… Validation passed\n",
      "[16:30:21] [INFO] ğŸš€ Starting preview generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Generating preview (10 synthetic stroke patients)...\n",
      "â±ï¸  This may take 1-2 minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:30:22] [INFO] â›“ï¸ Sorting column configs into a Directed Acyclic Graph\n",
      "[16:30:22] [INFO] ğŸ©º Running health checks for models...\n",
      "[16:30:24] [INFO]   |-- ğŸ‘€ Checking 'nvidia/nvidia-nemotron-nano-9b-v2'...\n",
      "[16:30:24] [INFO]   |-- âœ… Passed!\n",
      "[16:30:26] [INFO]   |-- ğŸ‘€ Checking 'nvidia/llama-3.3-nemotron-super-49b-v1.5'...\n",
      "[16:30:26] [INFO]   |-- âœ… Passed!\n",
      "[16:30:27] [INFO]   |-- ğŸ‘€ Checking 'mistralai/mistral-small-24b-instruct'...\n",
      "[16:30:27] [INFO]   |-- âœ… Passed!\n",
      "[16:30:28] [INFO]   |-- ğŸ‘€ Checking 'openai/gpt-oss-20b'...\n",
      "[16:30:28] [INFO]   |-- âœ… Passed!\n",
      "[16:30:29] [INFO]   |-- ğŸ‘€ Checking 'openai/gpt-oss-120b'...\n",
      "[16:30:29] [INFO]   |-- âœ… Passed!\n",
      "[16:30:30] [INFO]   |-- ğŸ‘€ Checking 'meta/llama-4-scout-17b-16e-instruct'...\n",
      "[16:30:30] [INFO]   |-- âœ… Passed!\n",
      "[16:30:30] [INFO] â³ Processing batch 1 of 1\n",
      "[16:30:30] [INFO] ğŸ² Preparing samplers to generate 10 records across 10 columns\n",
      "[16:30:30] [INFO] ğŸ“ Preparing llm-text column generation\n",
      "[16:30:30] [INFO]   |-- column name: 'medical_plausibility'\n",
      "[16:30:30] [INFO]   |-- model config:\n",
      "{\n",
      "    \"alias\": \"nemotron-super\",\n",
      "    \"model\": \"nvidia/llama-3.3-nemotron-super-49b-v1.5\",\n",
      "    \"inference_parameters\": {\n",
      "        \"temperature\": 0.6,\n",
      "        \"top_p\": 0.95,\n",
      "        \"max_tokens\": 32768,\n",
      "        \"max_parallel_requests\": 4,\n",
      "        \"timeout\": null\n",
      "    },\n",
      "    \"provider\": \"nvidiabuild\"\n",
      "}\n",
      "[16:30:35] [INFO] ğŸ™ Processing llm-text column 'medical_plausibility' with 4 concurrent workers\n",
      "[16:31:09] [INFO] ğŸ“Š Model usage summary:\n",
      "{\n",
      "    \"nvidia/llama-3.3-nemotron-super-49b-v1.5\": {\n",
      "        \"token_usage\": {\n",
      "            \"prompt_tokens\": 1980,\n",
      "            \"completion_tokens\": 8403,\n",
      "            \"total_tokens\": 10383\n",
      "        },\n",
      "        \"request_usage\": {\n",
      "            \"successful_requests\": 10,\n",
      "            \"failed_requests\": 0,\n",
      "            \"total_requests\": 10\n",
      "        },\n",
      "        \"tokens_per_second\": 270,\n",
      "        \"requests_per_minute\": 15\n",
      "    }\n",
      "}\n",
      "[16:31:09] [INFO] ğŸ“ Measuring dataset column statistics:\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'age'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'avg_glucose_level'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'bmi'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'gender_Male'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'hypertension_Yes'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'heart_disease_Yes'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'ever_married_Yes'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'Residence_type_Urban'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'work_type'\n",
      "[16:31:09] [INFO]   |-- ğŸ² column: 'smoking_status'\n",
      "[16:31:09] [INFO]   |-- ğŸ“ column: 'medical_plausibility'\n",
      "[16:31:09] [INFO] ğŸ Preview complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Preview generated successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” Generating preview (10 synthetic stroke patients)...\")\n",
    "print(\"â±ï¸  This may take 1-2 minutes...\\n\")\n",
    "\n",
    "preview = data_designer_client.preview(config_builder, num_records=10)\n",
    "\n",
    "print(\"\\nâœ“ Preview generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d69f7d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n",
       "<span style=\"font-style: italic\">                                                 Generated Columns                                                 </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Name                 </span>â”ƒ<span style=\"font-weight: bold\"> Value                                                                                    </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ age                  â”‚ 36.10690749580328                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ avg_glucose_level    â”‚ 262.3481281596456                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bmi                  â”‚ 52.23828873778147                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gender_Male          â”‚ 0                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ hypertension_Yes     â”‚ 0                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ heart_disease_Yes    â”‚ 0                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ ever_married_Yes     â”‚ 1                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Residence_type_Urban â”‚ 0                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ work_type            â”‚ Private                                                                                  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ smoking_status       â”‚ never smoked                                                                             â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ medical_plausibility â”‚ &lt;think&gt;                                                                                  â”‚\n",
       "â”‚                      â”‚ Okay, let's see. I need to rate the medical plausibility of this stroke patient's        â”‚\n",
       "â”‚                      â”‚ profile on a scale from 1 to 10. The patient is 36 years old, which is relatively young  â”‚\n",
       "â”‚                      â”‚ for a stroke. Usually, strokes are more common in older adults, like over 60. But I know â”‚\n",
       "â”‚                      â”‚ that younger people can have strokes too, especially if there are other risk factors.    â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Looking at the average glucose level: 262 mg/dL. That's pretty high. Normal fasting      â”‚\n",
       "â”‚                      â”‚ glucose is under 100, and anything over 126 is considered diabetes. So this person has   â”‚\n",
       "â”‚                      â”‚ diabetes, which is a major risk factor for stroke. But wait, the patient's age is 36. So â”‚\n",
       "â”‚                      â”‚ a 36-year-old with diabetes? That's possible, especially with the obesity epidemic. But  â”‚\n",
       "â”‚                      â”‚ how common is it?                                                                        â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ BMI is 52.238... That's extremely high. A BMI over 30 is obese, so 52 is class III       â”‚\n",
       "â”‚                      â”‚ obesity. That's a significant risk factor. Obesity is linked to hypertension, diabetes,  â”‚\n",
       "â”‚                      â”‚ heart disease, etc. But in this case, hypertension is 0 (No), and heart disease is 0     â”‚\n",
       "â”‚                      â”‚ (No). Hmm. So the patient has very high glucose and BMI but no hypertension or heart     â”‚\n",
       "â”‚                      â”‚ disease? That seems a bit conflicting. Usually, people with such high BMI and diabetes   â”‚\n",
       "â”‚                      â”‚ would have hypertension or other cardiovascular issues. But maybe not always. Maybe they â”‚\n",
       "â”‚                      â”‚ haven't developed it yet, or maybe they're on medication that controls it. But the data  â”‚\n",
       "â”‚                      â”‚ says hypertension is 0, so we have to take that as given.                                â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Smoking status is never smoked. Smoking is a risk factor, so not smoking is a positive,  â”‚\n",
       "â”‚                      â”‚ but in this case, the other factors are high. So the patient is young, has very high     â”‚\n",
       "â”‚                      â”‚ glucose, very high BMI, no hypertension, no heart disease, and never smoked.             â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Now, considering how these factors typically present together. Strokes in younger        â”‚\n",
       "â”‚                      â”‚ patients can happen, but they are less common. The presence of diabetes and severe       â”‚\n",
       "â”‚                      â”‚ obesity are strong risk factors. However, the absence of hypertension and heart disease  â”‚\n",
       "â”‚                      â”‚ is a bit odd because those are often comorbidities with diabetes and obesity. So maybe   â”‚\n",
       "â”‚                      â”‚ that combination is less typical.                                                        â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ But maybe in some cases, a young person could have undiagnosed or untreated diabetes     â”‚\n",
       "â”‚                      â”‚ leading to high glucose, and severe obesity without yet developing hypertension or heart â”‚\n",
       "â”‚                      â”‚ disease. It's possible, but how common is it? I think that the high BMI and glucose      â”‚\n",
       "â”‚                      â”‚ would usually be accompanied by other issues. So the plausibility might be lower because â”‚\n",
       "â”‚                      â”‚ of the missing hypertension and heart disease.                                           â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ So on a scale of 1-10, how realistic is this? The age is low, which is a point against   â”‚\n",
       "â”‚                      â”‚ typicalness. The high glucose and BMI are strong points for, but the lack of             â”‚\n",
       "â”‚                      â”‚ hypertension and heart disease might be against. So maybe a 5? Or 6? But I need to think â”‚\n",
       "â”‚                      â”‚ about real-world data. In actual stroke patients, even younger ones, do they often have  â”‚\n",
       "â”‚                      â”‚ multiple risk factors? Probably. So having only two major ones (glucose and BMI) but     â”‚\n",
       "â”‚                      â”‚ missing others might make it less typical. However, BMI and glucose are both very high,  â”‚\n",
       "â”‚                      â”‚ which might be enough.                                                                   â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Alternatively, maybe the absence of hypertension and heart disease makes this profile    â”‚\n",
       "â”‚                      â”‚ less plausible. Because in reality, people with such high BMI and glucose levels are     â”‚\n",
       "â”‚                      â”‚ more likely to have those other conditions. So this combination might be less common. So â”‚\n",
       "â”‚                      â”‚ maybe a 4 or 5? But I'm not sure.                                                        â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Another angle: the average age for stroke is increasing, but younger strokes are         â”‚\n",
       "â”‚                      â”‚ becoming more common due to rising obesity and diabetes rates. So a 36-year-old with     â”‚\n",
       "â”‚                      â”‚ diabetes and obesity could have a stroke even without other factors. But how often do    â”‚\n",
       "â”‚                      â”‚ they present without hypertension? Maybe in some cases.                                  â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ I think the key here is that while individual risk factors can exist alone, the          â”‚\n",
       "â”‚                      â”‚ combination of very high BMI and glucose without hypertension or heart disease might be  â”‚\n",
       "â”‚                      â”‚ less common. So the plausibility might be moderate. Maybe a 5 or 6. But I'm not certain. â”‚\n",
       "â”‚                      â”‚ Alternatively, if the high glucose and BMI are enough, then maybe higher. But the lack   â”‚\n",
       "â”‚                      â”‚ of other factors might lower it.                                                         â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ I'll go with 5. But I'm a bit uncertain. Maybe others would rate it higher.              â”‚\n",
       "â”‚                      â”‚ Alternatively, considering that the patient is very young, which is less typical, but    â”‚\n",
       "â”‚                      â”‚ the presence of two major risk factors (diabetes and obesity) could make it plausible.   â”‚\n",
       "â”‚                      â”‚ However, the absence of other common comorbidities might make it less typical. So 5      â”‚\n",
       "â”‚                      â”‚ seems reasonable.                                                                        â”‚\n",
       "â”‚                      â”‚ &lt;/think&gt;                                                                                 â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ 5                                                                                        â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "                                                                                                                   \n",
       "                                                    [index: 1]                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                                                                   \n",
       "\u001b[3m                                                 Generated Columns                                                 \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mName                \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mValue                                                                                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ age                  â”‚ 36.10690749580328                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ avg_glucose_level    â”‚ 262.3481281596456                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bmi                  â”‚ 52.23828873778147                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gender_Male          â”‚ 0                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ hypertension_Yes     â”‚ 0                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ heart_disease_Yes    â”‚ 0                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ ever_married_Yes     â”‚ 1                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Residence_type_Urban â”‚ 0                                                                                        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ work_type            â”‚ Private                                                                                  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ smoking_status       â”‚ never smoked                                                                             â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ medical_plausibility â”‚ <think>                                                                                  â”‚\n",
       "â”‚                      â”‚ Okay, let's see. I need to rate the medical plausibility of this stroke patient's        â”‚\n",
       "â”‚                      â”‚ profile on a scale from 1 to 10. The patient is 36 years old, which is relatively young  â”‚\n",
       "â”‚                      â”‚ for a stroke. Usually, strokes are more common in older adults, like over 60. But I know â”‚\n",
       "â”‚                      â”‚ that younger people can have strokes too, especially if there are other risk factors.    â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Looking at the average glucose level: 262 mg/dL. That's pretty high. Normal fasting      â”‚\n",
       "â”‚                      â”‚ glucose is under 100, and anything over 126 is considered diabetes. So this person has   â”‚\n",
       "â”‚                      â”‚ diabetes, which is a major risk factor for stroke. But wait, the patient's age is 36. So â”‚\n",
       "â”‚                      â”‚ a 36-year-old with diabetes? That's possible, especially with the obesity epidemic. But  â”‚\n",
       "â”‚                      â”‚ how common is it?                                                                        â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ BMI is 52.238... That's extremely high. A BMI over 30 is obese, so 52 is class III       â”‚\n",
       "â”‚                      â”‚ obesity. That's a significant risk factor. Obesity is linked to hypertension, diabetes,  â”‚\n",
       "â”‚                      â”‚ heart disease, etc. But in this case, hypertension is 0 (No), and heart disease is 0     â”‚\n",
       "â”‚                      â”‚ (No). Hmm. So the patient has very high glucose and BMI but no hypertension or heart     â”‚\n",
       "â”‚                      â”‚ disease? That seems a bit conflicting. Usually, people with such high BMI and diabetes   â”‚\n",
       "â”‚                      â”‚ would have hypertension or other cardiovascular issues. But maybe not always. Maybe they â”‚\n",
       "â”‚                      â”‚ haven't developed it yet, or maybe they're on medication that controls it. But the data  â”‚\n",
       "â”‚                      â”‚ says hypertension is 0, so we have to take that as given.                                â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Smoking status is never smoked. Smoking is a risk factor, so not smoking is a positive,  â”‚\n",
       "â”‚                      â”‚ but in this case, the other factors are high. So the patient is young, has very high     â”‚\n",
       "â”‚                      â”‚ glucose, very high BMI, no hypertension, no heart disease, and never smoked.             â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Now, considering how these factors typically present together. Strokes in younger        â”‚\n",
       "â”‚                      â”‚ patients can happen, but they are less common. The presence of diabetes and severe       â”‚\n",
       "â”‚                      â”‚ obesity are strong risk factors. However, the absence of hypertension and heart disease  â”‚\n",
       "â”‚                      â”‚ is a bit odd because those are often comorbidities with diabetes and obesity. So maybe   â”‚\n",
       "â”‚                      â”‚ that combination is less typical.                                                        â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ But maybe in some cases, a young person could have undiagnosed or untreated diabetes     â”‚\n",
       "â”‚                      â”‚ leading to high glucose, and severe obesity without yet developing hypertension or heart â”‚\n",
       "â”‚                      â”‚ disease. It's possible, but how common is it? I think that the high BMI and glucose      â”‚\n",
       "â”‚                      â”‚ would usually be accompanied by other issues. So the plausibility might be lower because â”‚\n",
       "â”‚                      â”‚ of the missing hypertension and heart disease.                                           â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ So on a scale of 1-10, how realistic is this? The age is low, which is a point against   â”‚\n",
       "â”‚                      â”‚ typicalness. The high glucose and BMI are strong points for, but the lack of             â”‚\n",
       "â”‚                      â”‚ hypertension and heart disease might be against. So maybe a 5? Or 6? But I need to think â”‚\n",
       "â”‚                      â”‚ about real-world data. In actual stroke patients, even younger ones, do they often have  â”‚\n",
       "â”‚                      â”‚ multiple risk factors? Probably. So having only two major ones (glucose and BMI) but     â”‚\n",
       "â”‚                      â”‚ missing others might make it less typical. However, BMI and glucose are both very high,  â”‚\n",
       "â”‚                      â”‚ which might be enough.                                                                   â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Alternatively, maybe the absence of hypertension and heart disease makes this profile    â”‚\n",
       "â”‚                      â”‚ less plausible. Because in reality, people with such high BMI and glucose levels are     â”‚\n",
       "â”‚                      â”‚ more likely to have those other conditions. So this combination might be less common. So â”‚\n",
       "â”‚                      â”‚ maybe a 4 or 5? But I'm not sure.                                                        â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ Another angle: the average age for stroke is increasing, but younger strokes are         â”‚\n",
       "â”‚                      â”‚ becoming more common due to rising obesity and diabetes rates. So a 36-year-old with     â”‚\n",
       "â”‚                      â”‚ diabetes and obesity could have a stroke even without other factors. But how often do    â”‚\n",
       "â”‚                      â”‚ they present without hypertension? Maybe in some cases.                                  â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ I think the key here is that while individual risk factors can exist alone, the          â”‚\n",
       "â”‚                      â”‚ combination of very high BMI and glucose without hypertension or heart disease might be  â”‚\n",
       "â”‚                      â”‚ less common. So the plausibility might be moderate. Maybe a 5 or 6. But I'm not certain. â”‚\n",
       "â”‚                      â”‚ Alternatively, if the high glucose and BMI are enough, then maybe higher. But the lack   â”‚\n",
       "â”‚                      â”‚ of other factors might lower it.                                                         â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ I'll go with 5. But I'm a bit uncertain. Maybe others would rate it higher.              â”‚\n",
       "â”‚                      â”‚ Alternatively, considering that the patient is very young, which is less typical, but    â”‚\n",
       "â”‚                      â”‚ the presence of two major risk factors (diabetes and obesity) could make it plausible.   â”‚\n",
       "â”‚                      â”‚ However, the absence of other common comorbidities might make it less typical. So 5      â”‚\n",
       "â”‚                      â”‚ seems reasonable.                                                                        â”‚\n",
       "â”‚                      â”‚ </think>                                                                                 â”‚\n",
       "â”‚                      â”‚                                                                                          â”‚\n",
       "â”‚                      â”‚ 5                                                                                        â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "                                                                                                                   \n",
       "                                                    [index: 1]                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61c72f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview dataset shape: (10, 11)\n",
      "\n",
      "Preview columns: ['age', 'avg_glucose_level', 'bmi', 'gender_Male', 'hypertension_Yes', 'heart_disease_Yes', 'ever_married_Yes', 'Residence_type_Urban', 'work_type', 'smoking_status', 'medical_plausibility']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>hypertension_Yes</th>\n",
       "      <th>heart_disease_Yes</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>medical_plausibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.522645</td>\n",
       "      <td>86.555396</td>\n",
       "      <td>44.485638</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.106907</td>\n",
       "      <td>262.348128</td>\n",
       "      <td>52.238289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.081645</td>\n",
       "      <td>186.497012</td>\n",
       "      <td>17.270724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.715803</td>\n",
       "      <td>264.722253</td>\n",
       "      <td>27.619640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.167543</td>\n",
       "      <td>259.310869</td>\n",
       "      <td>39.984499</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.826247</td>\n",
       "      <td>137.896119</td>\n",
       "      <td>55.229181</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61.609836</td>\n",
       "      <td>67.032915</td>\n",
       "      <td>36.118685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81.303494</td>\n",
       "      <td>184.890897</td>\n",
       "      <td>56.377818</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40.747273</td>\n",
       "      <td>64.155775</td>\n",
       "      <td>36.614394</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56.117794</td>\n",
       "      <td>147.119623</td>\n",
       "      <td>52.858248</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  avg_glucose_level        bmi  gender_Male  hypertension_Yes  \\\n",
       "0  59.522645          86.555396  44.485638            1                 0   \n",
       "1  36.106907         262.348128  52.238289            0                 0   \n",
       "2  38.081645         186.497012  17.270724            1                 1   \n",
       "3  21.715803         264.722253  27.619640            0                 0   \n",
       "4  47.167543         259.310869  39.984499            1                 0   \n",
       "5  15.826247         137.896119  55.229181            1                 0   \n",
       "6  61.609836          67.032915  36.118685            0                 0   \n",
       "7  81.303494         184.890897  56.377818            1                 0   \n",
       "8  40.747273          64.155775  36.614394            1                 0   \n",
       "9  56.117794         147.119623  52.858248            1                 1   \n",
       "\n",
       "   heart_disease_Yes  ever_married_Yes  Residence_type_Urban      work_type  \\\n",
       "0                  0                 1                     0        Private   \n",
       "1                  0                 1                     0        Private   \n",
       "2                  0                 0                     1        Private   \n",
       "3                  0                 1                     1        Private   \n",
       "4                  0                 1                     0        Private   \n",
       "5                  0                 1                     0        Private   \n",
       "6                  1                 1                     0        Private   \n",
       "7                  1                 1                     1  Self-employed   \n",
       "8                  0                 1                     1        Private   \n",
       "9                  0                 1                     1  Self-employed   \n",
       "\n",
       "    smoking_status  medical_plausibility  \n",
       "0     never smoked                     6  \n",
       "1     never smoked                     5  \n",
       "2  formerly smoked                     6  \n",
       "3     never smoked                     5  \n",
       "4     never smoked                     6  \n",
       "5  formerly smoked                     1  \n",
       "6  formerly smoked                     7  \n",
       "7     never smoked                     7  \n",
       "8  formerly smoked                     5  \n",
       "9     never smoked                     8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_df = preview.dataset\n",
    "print(f\"Preview dataset shape: {preview_df.shape}\")\n",
    "print(f\"\\nPreview columns: {preview_df.columns.tolist()}\")\n",
    "preview_df['medical_plausibility'] = preview_df['medical_plausibility'].apply(extract_plausibility_score)\n",
    "preview_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db92f6db",
   "metadata": {},
   "source": [
    "## 5. Generate Full Synthetic Dataset\n",
    "\n",
    "**âš ï¸ Important**: This step will take time (10-20 minutes) and consume API credits (~$0.50-2.00)\n",
    "\n",
    "Choose your augmentation strategy:\n",
    "- **Conservative** (2x minority): 249 samples (recommended for testing)\n",
    "- **Moderate** (4x minority): 747 samples\n",
    "- **Aggressive** (full balance): ~4,612 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a385740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original minority class size: 249\n",
      "Original majority class size: 4861\n",
      "\n",
      "Generation options:\n",
      "  Conservative (2x minority): 249 samples\n",
      "  Moderate (4x minority): 747 samples\n",
      "  Aggressive (full balance): 4612 samples\n",
      "\n",
      "ğŸ¯ Will generate: 249 synthetic stroke patients\n",
      "âš ï¸  Uncomment the cell below to run the generation\n"
     ]
    }
   ],
   "source": [
    "# Calculate generation options\n",
    "num_minority = len(stroke_cases)\n",
    "num_majority = len(non_stroke_cases)\n",
    "\n",
    "print(f\"Original minority class size: {num_minority}\")\n",
    "print(f\"Original majority class size: {num_majority}\")\n",
    "print(f\"\\nGeneration options:\")\n",
    "print(f\"  Conservative (2x minority): {num_minority} samples\")\n",
    "print(f\"  Moderate (4x minority): {num_minority * 3} samples\")\n",
    "print(f\"  Aggressive (full balance): {num_majority - num_minority} samples\")\n",
    "\n",
    "# Choose strategy - CONSERVATIVE by default (recommended for testing)\n",
    "num_to_generate = num_minority  # Start with conservative\n",
    "\n",
    "print(f\"\\nğŸ¯ Will generate: {num_to_generate} synthetic stroke patients\")\n",
    "print(f\"âš ï¸  Uncomment the cell below to run the generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3de34247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUGGING: What endpoints are being called?\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NeMoDataDesignerClient' object has no attribute 'base_url'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDEBUGGING: What endpoints are being called?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClient base_url:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mdata_designer_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbase_url\u001b[49m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClient has .preview method:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mhasattr\u001b[39m(data_designer_client, \u001b[33m'\u001b[39m\u001b[33mpreview\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClient has .create method:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mhasattr\u001b[39m(data_designer_client, \u001b[33m'\u001b[39m\u001b[33mcreate\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'NeMoDataDesignerClient' object has no attribute 'base_url'"
     ]
    }
   ],
   "source": [
    "# DEBUG: Let's understand what's different between preview and create\n",
    "# First, let's enable debug logging to see what endpoints are being called\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Also let's check if there's a way to see the actual request being made\n",
    "import httpx\n",
    "\n",
    "# Create a custom client with request logging\n",
    "print(\"=\" * 70)\n",
    "print(\"DEBUGGING: What endpoints are being called?\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nClient base_url:\", data_designer_client.base_url)\n",
    "print(\"Client has .preview method:\", hasattr(data_designer_client, 'preview'))\n",
    "print(\"Client has .create method:\", hasattr(data_designer_client, 'create'))\n",
    "print(\"\\nThe preview() call succeeded, which means the API was working\")\n",
    "print(\"The create() call fails with 404, which suggests:\")\n",
    "print(\"  1. Different endpoint path for create vs preview\")\n",
    "print(\"  2. Service became unavailable between calls\")\n",
    "print(\"  3. Different authentication/quota for create\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5615e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:18:06] [INFO] ğŸ¨ Creating Data Designer generation job\n",
      "[16:18:06] [INFO] âœ… Validation passed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ­ Generating 249 synthetic stroke patients...\n",
      "â±ï¸  This will take several minutes. Please wait...\n",
      "\n"
     ]
    },
    {
     "ename": "DataDesignerClientError",
     "evalue": "â€¼ï¸ Something went wrong!\n404 page not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDataDesignerClientError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ­ Generating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_to_generate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m synthetic stroke patients...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâ±ï¸  This will take several minutes. Please wait...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m synthetic_result = \u001b[43mdata_designer_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_records\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_to_generate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_until_done\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m synthetic_df = synthetic_result.dataset\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ“ Generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(synthetic_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m synthetic samples!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Work/class-imbalance-testing/.venv/lib/python3.12/site-packages/nemo_microservices/data_designer/client/data_designer_client.py:117\u001b[39m, in \u001b[36mNeMoDataDesignerClient.create\u001b[39m\u001b[34m(self, config_builder, num_records, wait_until_done, name, project)\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[43mhandle_api_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Work/class-imbalance-testing/.venv/lib/python3.12/site-packages/nemo_microservices/data_designer/client/errors.py:31\u001b[39m, in \u001b[36mhandle_api_exceptions\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DataDesignerConfigValidationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâ€¼ï¸ Config validation failed!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DataDesignerClientError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâ€¼ï¸ Something went wrong!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mDataDesignerClientError\u001b[39m: â€¼ï¸ Something went wrong!\n404 page not found"
     ]
    }
   ],
   "source": [
    "# UNCOMMENT AND RUN THIS CELL TO GENERATE SYNTHETIC DATA\n",
    "# âš ï¸ This will take 10-20 minutes and consume API credits!\n",
    "\n",
    "print(f\"ğŸ­ Generating {num_to_generate} synthetic stroke patients...\")\n",
    "print(f\"â±ï¸  This will take several minutes. Please wait...\\n\")\n",
    "\n",
    "synthetic_result = data_designer_client.create(config_builder, num_records=num_to_generate, wait_until_done=True)\n",
    "synthetic_df = synthetic_result.dataset\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(synthetic_df)} synthetic samples!\")\n",
    "print(f\"Synthetic dataset shape: {synthetic_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035d080",
   "metadata": {},
   "source": [
    "## 6. Load Scaler for Synthetic Data\n",
    "\n",
    "We need to scale the synthetic data using the same scaler fitted on the original training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cfce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the fitted scaler from feature engineering\n",
    "scaler_path = '../data/robust_scaler.pkl'\n",
    "robust_scaler = joblib.load(scaler_path)\n",
    "\n",
    "print(f\"âœ“ Loaded RobustScaler from: {scaler_path}\")\n",
    "print(f\"   This scaler will be applied to numerical features in synthetic data\")\n",
    "print(f\"   to ensure consistency with the training data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7052f0",
   "metadata": {},
   "source": [
    "## 7. Process Generated Data\n",
    "\n",
    "Convert NDD output to match original dataset format and **scale numerical features**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1353ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_generated_data(generated_df, scaler, min_plausibility=None):\n",
    "    \"\"\"\n",
    "    Convert generated data to match original dataset format and scale numerical features\n",
    "    \n",
    "    Args:\n",
    "        generated_df: DataFrame from NDD (with UNSCALED numerical features)\n",
    "        scaler: Fitted RobustScaler to apply to numerical features\n",
    "        min_plausibility: Minimum plausibility score to keep (if using LLM validation)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ Processing generated data...\")\n",
    "    \n",
    "    # Filter by plausibility if specified\n",
    "    if min_plausibility is not None and 'medical_plausibility' in generated_df.columns:\n",
    "        original_len = len(generated_df)\n",
    "        # Extract just the numeric value from the plausibility column\n",
    "        # (handles LLM responses with <think> tags and explanations)\n",
    "        generated_df['plausibility_score'] = generated_df['medical_plausibility'].apply(\n",
    "            extract_plausibility_score\n",
    "        )\n",
    "        generated_df = generated_df[\n",
    "            generated_df['plausibility_score'] >= min_plausibility\n",
    "        ]\n",
    "        print(f\"   âœ“ Extracted plausibility scores (1-10) from LLM responses\")\n",
    "        print(f\"   Filtered by plausibility â‰¥{min_plausibility}: {original_len} â†’ {len(generated_df)}\")\n",
    "    \n",
    "    processed = pd.DataFrame()\n",
    "    \n",
    "    # Numerical features (UNSCALED from NDD)\n",
    "    numerical_features = ['age', 'avg_glucose_level', 'bmi']\n",
    "    processed[numerical_features] = generated_df[numerical_features].copy()\n",
    "    \n",
    "    print(f\"   ğŸ“Š Before scaling: age range [{processed['age'].min():.1f}, {processed['age'].max():.1f}]\")\n",
    "    \n",
    "    # Apply the fitted scaler to numerical features\n",
    "    processed[numerical_features] = scaler.transform(processed[numerical_features])\n",
    "    \n",
    "    print(f\"   âœ“ Scaled numerical features using fitted RobustScaler\")\n",
    "    print(f\"   ğŸ“Š After scaling: age range [{processed['age'].min():.3f}, {processed['age'].max():.3f}]\")\n",
    "    \n",
    "    # Binary features\n",
    "    processed['gender_Male'] = generated_df['gender_Male'].astype(int)\n",
    "    processed['hypertension_Yes'] = generated_df['hypertension_Yes'].astype(int)\n",
    "    processed['heart_disease_Yes'] = generated_df['heart_disease_Yes'].astype(int)\n",
    "    processed['ever_married_Yes'] = generated_df['ever_married_Yes'].astype(int)\n",
    "    processed['Residence_type_Urban'] = generated_df['Residence_type_Urban'].astype(int)\n",
    "    \n",
    "    # One-hot encode work_type\n",
    "    processed['work_type_Never_worked'] = (generated_df['work_type'] == 'Never_worked').astype(int)\n",
    "    processed['work_type_Private'] = (generated_df['work_type'] == 'Private').astype(int)\n",
    "    processed['work_type_Self-employed'] = (generated_df['work_type'] == 'Self-employed').astype(int)\n",
    "    processed['work_type_children'] = (generated_df['work_type'] == 'children').astype(int)\n",
    "    \n",
    "    # One-hot encode smoking_status\n",
    "    processed['smoking_status_formerly smoked'] = (generated_df['smoking_status'] == 'formerly smoked').astype(int)\n",
    "    processed['smoking_status_never smoked'] = (generated_df['smoking_status'] == 'never smoked').astype(int)\n",
    "    processed['smoking_status_smokes'] = (generated_df['smoking_status'] == 'smokes').astype(int)\n",
    "    \n",
    "    # Add stroke label (all synthetic samples are stroke cases)\n",
    "    processed['stroke'] = 1\n",
    "    \n",
    "    print(f\"   âœ“ Processed and scaled {len(processed)} samples\")\n",
    "    return processed\n",
    "\n",
    "# Test with preview data\n",
    "processed_preview = process_generated_data(\n",
    "    preview_df, \n",
    "    scaler=robust_scaler,\n",
    "    min_plausibility=7 if use_llm_validation else None\n",
    ")\n",
    "print(f\"\\nProcessed preview shape: {processed_preview.shape}\")\n",
    "print(f\"Processed columns ({len(processed_preview.columns)}): {processed_preview.columns.tolist()}\")\n",
    "processed_preview.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71854dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the full synthetic dataset (uncomment after generation)\n",
    "# processed_synthetic = process_generated_data(\n",
    "#     synthetic_df,\n",
    "#     scaler=robust_scaler,\n",
    "#     min_plausibility=7 if use_llm_validation else None\n",
    "# )\n",
    "# print(f\"Final processed synthetic data shape: {processed_synthetic.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24452d80",
   "metadata": {},
   "source": [
    "## 8. Combine Original and Synthetic Data\n",
    "\n",
    "Create the augmented dataset by combining **scaled** original data with **scaled** synthetic samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ea15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT AFTER GENERATING AND PROCESSING SYNTHETIC DATA\n",
    "\n",
    "# print(\"ğŸ”— Combining original and synthetic data...\")\n",
    "\n",
    "# # Load the SCALED original data (not the unscaled version we used for NDD)\n",
    "# df_original = pd.read_csv('../data/stroke_data_prepared.csv')\n",
    "\n",
    "# # Remove ID column from original if present\n",
    "# df_original = df_original.drop('id', axis=1) if 'id' in df_original.columns else df_original.copy()\n",
    "\n",
    "# # Ensure column order matches\n",
    "# processed_synthetic = processed_synthetic[df_original.columns]\n",
    "\n",
    "# # Combine SCALED original + SCALED synthetic\n",
    "# df_augmented = pd.concat([df_original, processed_synthetic], ignore_index=True)\n",
    "\n",
    "# print(f\"\\nğŸ“Š Dataset Summary:\")\n",
    "# print(f\"   Original (scaled): {len(df_original)} samples\")\n",
    "# print(f\"   Synthetic (scaled): {len(processed_synthetic)} samples\")\n",
    "# print(f\"   Augmented: {len(df_augmented)} samples\")\n",
    "\n",
    "# print(f\"\\nğŸ“ˆ Augmented Class Distribution:\")\n",
    "# print(df_augmented['stroke'].value_counts())\n",
    "# print(f\"\\nğŸ“Š Augmented Class Distribution (%):\")\n",
    "# print(df_augmented['stroke'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# print(f\"\\nâœ“ Augmented dataset created (all features properly scaled)!\")\n",
    "\n",
    "print(\"âš ï¸ Uncomment after generating synthetic data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86661c",
   "metadata": {},
   "source": [
    "## 9. Train XGBoost Model on Augmented Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT AFTER CREATING AUGMENTED DATASET\n",
    "\n",
    "# print(\"ğŸ¤– Training XGBoost model on NDD-augmented data...\\n\")\n",
    "\n",
    "# # Split features and target\n",
    "# X_augmented = df_augmented.drop('stroke', axis=1)\n",
    "# y_augmented = df_augmented['stroke']\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_augmented, y_augmented,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=y_augmented\n",
    "# )\n",
    "\n",
    "# print(f\"Training set shape: {X_train.shape}\")\n",
    "# print(f\"Testing set shape: {X_test.shape}\")\n",
    "# print(f\"\\nTraining class distribution:\")\n",
    "# print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "# # Train model\n",
    "# ndd_model = xgb.XGBClassifier(\n",
    "#     tree_method='hist',\n",
    "#     eval_metric='aucpr',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# print(\"\\nâ³ Training model...\")\n",
    "# ndd_model.fit(X_train, y_train)\n",
    "# print(\"âœ“ Training complete!\")\n",
    "\n",
    "print(\"âš ï¸ Uncomment after creating augmented dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf771c2",
   "metadata": {},
   "source": [
    "## 10. Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT AFTER TRAINING MODEL\n",
    "\n",
    "# print(\"ğŸ“Š Evaluating model performance...\\n\")\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = ndd_model.predict(X_test)\n",
    "# y_pred_proba = ndd_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # Calculate metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "# pr_auc = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "# print(\"NeMo Data Designer Model Performance\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall:    {recall:.4f}\")\n",
    "# print(f\"F1 Score:  {f1:.4f}\")\n",
    "# print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "# print(f\"PR-AUC:    {pr_auc:.4f}\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# print(\"\\nğŸ“‹ Detailed Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred, target_names=['No Stroke', 'Stroke']))\n",
    "\n",
    "# print(\"\\nğŸ“Š Confusion Matrix:\")\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)\n",
    "# print(f\"\\nTrue Negatives: {cm[0,0]}\")\n",
    "# print(f\"False Positives: {cm[0,1]}\")\n",
    "# print(f\"False Negatives: {cm[1,0]}\")\n",
    "# print(f\"True Positives: {cm[1,1]}\")\n",
    "\n",
    "print(\"âš ï¸ Uncomment after training model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f4a33",
   "metadata": {},
   "source": [
    "## 11. Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT AFTER EVALUATION\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=True)\n",
    "# ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "# ax.set_ylabel('True Label', fontsize=12)\n",
    "# ax.set_title('Confusion Matrix - NeMo Data Designer Model', fontsize=14, fontweight='bold')\n",
    "# ax.set_xticklabels(['No Stroke', 'Stroke'])\n",
    "# ax.set_yticklabels(['No Stroke', 'Stroke'])\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"âš ï¸ Uncomment after evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d4f4a",
   "metadata": {},
   "source": [
    "## 12. Compare with Other Techniques\n",
    "\n",
    "Compare NDD results with Base Model, Scale Pos Weight, and SMOTE approaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45208ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison dataframe\n",
    "# Fill in your actual values from other notebooks\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Technique': [\n",
    "        'Base Model',\n",
    "        'Scale Pos Weight',\n",
    "        'SMOTE',\n",
    "        'NeMo Data Designer'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        0.0,  # Fill in from base-model.ipynb\n",
    "        0.0,  # Fill in from scale-pos-weight-model.ipynb\n",
    "        0.0,  # Fill in from smote-model.ipynb\n",
    "        0.0,  # Will be filled after running NDD model\n",
    "    ],\n",
    "    'Precision': [\n",
    "        0.0,  # Fill in from base-model.ipynb\n",
    "        0.0,  # Fill in from scale-pos-weight-model.ipynb\n",
    "        0.0,  # Fill in from smote-model.ipynb\n",
    "        0.0,  # Will be filled after running NDD model\n",
    "    ],\n",
    "    'Recall': [\n",
    "        0.0,  # Fill in from base-model.ipynb\n",
    "        0.0,  # Fill in from scale-pos-weight-model.ipynb\n",
    "        0.0,  # Fill in from smote-model.ipynb\n",
    "        0.0,  # Will be filled after running NDD model\n",
    "    ],\n",
    "    'F1 Score': [\n",
    "        0.0,  # Fill in from base-model.ipynb\n",
    "        0.0,  # Fill in from scale-pos-weight-model.ipynb\n",
    "        0.0,  # Fill in from smote-model.ipynb\n",
    "        0.0,  # Will be filled after running NDD model\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        0.0,  # Fill in from base-model.ipynb\n",
    "        0.0,  # Fill in from scale-pos-weight-model.ipynb\n",
    "        0.0,  # Fill in from smote-model.ipynb\n",
    "        0.0,  # Will be filled after running NDD model\n",
    "    ],\n",
    "    'PR-AUC': [\n",
    "        0.0,  # Fill in from base-model.ipynb\n",
    "        0.0,  # Fill in from scale-pos-weight-model.ipynb\n",
    "        0.0,  # Fill in from smote-model.ipynb\n",
    "        0.0,  # Will be filled after running NDD model\n",
    "    ],\n",
    "})\n",
    "\n",
    "# After running NDD model, update the last row with your actual metrics:\n",
    "# comparison_df.loc[3, 'Accuracy'] = accuracy\n",
    "# comparison_df.loc[3, 'Precision'] = precision\n",
    "# comparison_df.loc[3, 'Recall'] = recall\n",
    "# comparison_df.loc[3, 'F1 Score'] = f1\n",
    "# comparison_df.loc[3, 'ROC-AUC'] = roc_auc\n",
    "# comparison_df.loc[3, 'PR-AUC'] = pr_auc\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Performance Comparison Across All Techniques\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nâš ï¸ Fill in actual values from your other notebooks after running all models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8484b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of metrics (uncomment after filling in comparison_df with actual values)\n",
    "\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "# axes = axes.ravel()\n",
    "\n",
    "# metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC', 'PR-AUC']\n",
    "# colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "# for idx, metric in enumerate(metrics):\n",
    "#     ax = axes[idx]\n",
    "#     bars = ax.bar(comparison_df['Technique'], comparison_df[metric], color=colors)\n",
    "#     ax.set_title(metric, fontsize=12, fontweight='bold')\n",
    "#     ax.set_ylabel('Score', fontsize=10)\n",
    "#     ax.set_ylim(0, 1)\n",
    "#     ax.tick_params(axis='x', rotation=45)\n",
    "#     ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "#     # Add value labels on bars\n",
    "#     for bar in bars:\n",
    "#         height = bar.get_height()\n",
    "#         if height > 0:  # Only show if value is filled in\n",
    "#             ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "#                     f'{height:.3f}',\n",
    "#                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.suptitle('Performance Comparison: All Class Imbalance Techniques', \n",
    "#              fontsize=14, fontweight='bold', y=1.02)\n",
    "# plt.show()\n",
    "\n",
    "print(\"âš ï¸ Uncomment after filling in comparison metrics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486c31e",
   "metadata": {},
   "source": [
    "## 13. Key Insights & Next Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ef6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"WORKFLOW SUMMARY - NeMo Data Designer for Stroke Prediction\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nâœ… What You've Done:\")\n",
    "print(\"   1. Loaded UNSCALED data for NDD (real ages, glucose, BMI)\")\n",
    "print(\"   2. Configured NDD samplers based on actual stroke patient distributions\")\n",
    "print(\"   3. Added LLM-based medical coherence validation with real values\")\n",
    "print(\"   4. Generated preview to verify configuration\")\n",
    "print(\"   5. Loaded fitted scaler to apply to synthetic data\")\n",
    "print(\"   6. Set up processing pipeline that scales synthetic samples\")\n",
    "\n",
    "print(\"\\nğŸ”„ To Complete the Experiment:\")\n",
    "print(\"   1. Uncomment Cell 25 to generate full synthetic dataset (~10-20 min)\")\n",
    "print(\"   2. Uncomment Cell 30 to process and SCALE the generated data\")\n",
    "print(\"   3. Uncomment Cell 32 to combine SCALED original + SCALED synthetic\")\n",
    "print(\"   4. Uncomment Cell 34 to train XGBoost model\")\n",
    "print(\"   5. Uncomment Cell 36 to evaluate and get metrics\")\n",
    "print(\"   6. Fill in comparison table with metrics from all models\")\n",
    "print(\"   7. Uncomment visualization cells to compare results\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Expected Insights:\")\n",
    "print(\"   â€¢ NDD may perform similarly to SMOTE (possibly slightly worse)\")\n",
    "print(\"   â€¢ LLM coherence validation is NDD's unique advantage\")\n",
    "print(\"   â€¢ SMOTE is faster and more cost-effective for numerical data\")\n",
    "print(\"   â€¢ NDD would excel with text-based medical features (clinical notes)\")\n",
    "\n",
    "print(\"\\nğŸ“Š Key Considerations:\")\n",
    "print(\"   â€¢ Time: 10-20 minutes for generation\")\n",
    "print(\"   â€¢ Cost: ~$0.50-2.00 in API credits\")\n",
    "print(\"   â€¢ Learning: Valuable experience with LLM-based synthetic data\")\n",
    "print(\"   â€¢ IMPORTANT: NDD uses unscaled data, then we scale synthetic samples\")\n",
    "print(\"     This allows LLM to evaluate real medical values (age=67, not 0.72)\")\n",
    "\n",
    "print(\"\\nğŸ¯ Recommendations:\")\n",
    "print(\"   â€¢ Use Conservative generation (249 samples) for initial testing\")\n",
    "print(\"   â€¢ Keep plausibility threshold at 7+ for quality\")\n",
    "print(\"   â€¢ Compare honestly with SMOTE - document when each is better\")\n",
    "print(\"   â€¢ Save this approach for future text-based medical projects\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ“ Notebook Ready! Uncomment cells as you progress through the workflow.\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d77240",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### ğŸ“š Documentation\n",
    "- **NDD Implementation Guide**: `../NDD_IMPLEMENTATION_GUIDE.md`\n",
    "- **Quick Start Guide**: `../README_NDD.md`\n",
    "- **Python Script Version**: `../ndd_stroke_augmentation.py`\n",
    "\n",
    "### ğŸ”§ Configuration Options\n",
    "\n",
    "**Model Selection** (Cell 3):\n",
    "```python\n",
    "model_alias = \"nemotron-super\"  # Recommended\n",
    "# Options: nemotron-nano-v2, nemotron-super, mistral-small, gpt-oss-120b\n",
    "```\n",
    "\n",
    "**LLM Validation** (Cell 18):\n",
    "```python\n",
    "use_llm_validation = True  # Set False to skip (faster, cheaper)\n",
    "```\n",
    "\n",
    "**Plausibility Threshold** (Cell 27):\n",
    "```python\n",
    "min_plausibility=7  # Only keep samples with score â‰¥7 (1-10 scale)\n",
    "```\n",
    "\n",
    "**Generation Amount** (Cell 24):\n",
    "```python\n",
    "num_to_generate = num_minority  # Conservative (249)\n",
    "# num_to_generate = num_minority * 3  # Moderate (747)\n",
    "# num_to_generate = num_majority - num_minority  # Aggressive (4,612)\n",
    "```\n",
    "\n",
    "### âš ï¸ Important Notes\n",
    "\n",
    "1. **Generation is commented out by default** - Uncomment Cell 25 when ready\n",
    "2. **Cost**: ~$0.50-2.00 for conservative generation with nemotron-super\n",
    "3. **Time**: ~10-20 minutes for 249 samples\n",
    "4. **Quality over quantity**: Use plausibility filtering for better results\n",
    "5. **Realistic expectations**: NDD may not outperform SMOTE for numerical data\n",
    "\n",
    "### ğŸ’­ Honest Assessment\n",
    "\n",
    "**When NDD is worth it:**\n",
    "- Text-based features (clinical notes, patient narratives)\n",
    "- Need medical coherence validation\n",
    "- Learning LLM-based synthetic data generation\n",
    "- Complex categorical relationships\n",
    "\n",
    "**When SMOTE is better:**\n",
    "- Purely numerical data (like this stroke dataset)\n",
    "- Need speed and efficiency\n",
    "- Limited budget/API credits\n",
    "- Production pipelines\n",
    "\n",
    "### ğŸ“ Citation\n",
    "\n",
    "If you use NeMo Data Designer in your research:\n",
    "```\n",
    "NVIDIA NeMo Microservices - Data Designer\n",
    "https://build.nvidia.com/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to proceed?** Start by running cells 1-20 to generate and verify your preview, then uncomment the remaining cells as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb63f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
